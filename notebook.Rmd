---
title: "BDA project"
author: "Anonymous"
output:
  pdf_document:
    toc: yes
    toc_depth: 1
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '1'
  word_document:
    toc: yes
    toc_depth: '1'
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Loaded packages

```{r, echo=TRUE}
suppressPackageStartupMessages({
  library(tidyr)
  library(dplyr)
  library(knitr)
  library(rstan)
  library(rstanarm)
  library(bayesplot)
  library(aaltobda)
  options(mc.cores = parallel::detectCores())
  library(loo)
  library(ggplot2)
  library(gridExtra)
  library(bayesplot)
})
```

```{r}
SEED <- 1472652
set.seed(SEED)
options(max.print=1000000)
```

# Utility functions

```{r}
# The code in stan_utility.R was copied from https://github.com/avehtari/BDA_R_demos/blob/master/demos_rstan/stan_utility.R
source('stan_utility.R')

# plot a histogram with percentages instead of frequencies 
partial_percentage_hist <- function(
  data,
  upper_limit
) {
  truncated_data = data[data < upper_limit]
  h <- hist(truncated_data, plot = FALSE)
  h$density <- h$counts / sum(h$counts) * 100
  plot(h, freq=F, ylab='Percentage', col = '#6eb5db')
}

# prior preditive checking for hierarchical model
check_prior_hierarchical <- function(
  full_grouped_data, 
  mu_group_alpha_sd,
  mu_group_beta_sd,
  tau_alpha_sd,
  tau_beta_sd
) {
  N = 5000 # number of samples to draw
  K = 11 # number of hierarchical groups
  D = 10 # number of datapoints for each group (i.e. number of years)
  
  counter_1e7 = 0
  counter_1e6 = 0
  counter_1e5 = 0
  counter_1e4 = 0
  
  y_pred_prior = array(rep(1, N*K*D), dim=c(N, K, D-1)) # initialize an empty array to hold data
  
  for (j in 1:K) { # number of age groups
    mu_group_alpha = rnorm(N, 0, mu_group_alpha_sd)
      
    for (q in 1:N) {
      mu_group_beta = rnorm(1, 0, mu_group_beta_sd)
      
      while (mu_group_beta < 0) {
        mu_group_beta = rnorm(1, 0, mu_group_beta_sd)
      }
      
      while (TRUE) {
        tau_alpha = rcauchy(1, 0, tau_alpha_sd)
        tau_beta = rcauchy(1, 0, tau_beta_sd)
        
        while (tau_alpha < 0 || tau_beta < 0) {
          tau_alpha = rcauchy(1, 0, tau_alpha_sd)
          tau_beta = rcauchy(1, 0, tau_beta_sd)
        }
        
        alpha = rnorm(1, mu_group_alpha[q], tau_alpha)
        beta = rnorm(1, mu_group_beta, tau_beta)
        
        if (beta >= 0) {
          passed = TRUE
          # starting with 2nd day becase AR(1) model is used (no meaningful fit for the first point)
          for (i in 2:D) { 
            mu = alpha + beta * full_grouped_data[j, i-1]
            if (mu < 0) {
              passed = FALSE
              break
            }
          }
          
          if (passed) {
            break
          }  
        }
      }
      
      # starting with 2nd day becase AR(1) model is used
      for (i in 2:D) { 
        mu = alpha + beta * full_grouped_data[j, i-1]
        
        if (mu > 0) {
          y_pred = rpois(1, mu)
          
          if (y_pred > 1e7) {
            counter_1e7 = counter_1e7 + 1
          }
          if (y_pred > 1e6) {
            counter_1e6 = counter_1e6 + 1
          }
          if (y_pred > 1e5) {
            counter_1e5 = counter_1e5 + 1
          }
          if (y_pred > 1e4) {
            counter_1e4 = counter_1e4 + 1
          }
    
          y_pred_prior[q, j, i-1] <- y_pred
        }
      }
    }
  }
  
  print(counter_1e7 / (N * K * (D - 1)))
  print(counter_1e6 / (N * K * (D - 1)))
  print(counter_1e5 / (N * K * (D - 1)))
  print(counter_1e4 / (N * K * (D - 1))) 
  
  plot1 <- partial_percentage_hist(y_pred_prior, 1e6)
  plot2 <- partial_percentage_hist(y_pred_prior, 1e5)
  plot3 <- partial_percentage_hist(y_pred_prior, 1e4)
}

# HMC specific convergence diagnostics
print_fit_diagnostic <- function(fit, tree_depth) {
  check_treedepth(fit, tree_depth)
  check_div(fit)
}

# do PSIS-LOO for the fit ommitting first 4 years out of 10
get_loo_diagnostics <- function(fit) {
  N <- 99
  # our fit does not have data for the first year already, so we only need to remove 3 years from the beginning
  L <- 11 * 3
  
  log_lik_all <- extract_log_lik(fit, merge_chains = FALSE)
  log_lik <- log_lik_all[, , (L+1):N]
  
  r_eff <- relative_eff(exp(log_lik))
  loo(log_lik, r_eff = r_eff)
}

########
# The code below is adapted from http://mc-stan.org/loo/articles/loo2-lfo.html
# more stable than log(sum(exp(x))) 
log_sum_exp <- function(x) {
  max_x <- max(x)  
  max_x + log(sum(exp(x - max_x)))
}

# more stable than log(mean(exp(x)))
log_mean_exp <- function(x) {
  log_sum_exp(x) - log(length(x))
}

# compute log of raw importance ratios
# sums over observations *not* over posterior samples
sum_log_ratios <- function(ll, ids = NULL) {
  if (!is.null(ids)) ll <- ll[, ids, drop = FALSE]
  - rowSums(ll)
}

# for printing comparisons later
rbind_print <- function(...) {
  round(rbind(...), digits = 2)
}

get_lfo_cv_results_hierarchical <- function(
  mu_group_alpha_prior_sd,
  mu_group_beta_prior_sd,
  tau_alpha_prior_sd,
  tau_beta_prior_sd
) {
  N = 10 # numebr of data points for eahc group
  L = 4 # number of datapoints to skip from the start
  K = 11 # number of age groups
  
  loglik_exact_hierarchical <- matrix(nrow = 10000, ncol = N * K)
  
  for (i in seq(N, L+1, -1)) {
    full_grouped_data_i <- full_grouped_data[, (1:i)]
    stan_data_i = list(
      N = (i-1) * 11,
      K = 11,
      x = rep(1:nrow(full_grouped_data_i), i - 1),
      y = tail(c(full_grouped_data_i), -11),
      y0 = head(c(full_grouped_data_i), 11),
      mu_group_alpha_prior_sd = mu_group_alpha_prior_sd,
      mu_group_beta_prior_sd = mu_group_beta_prior_sd,
      tau_alpha_prior_sd = tau_alpha_prior_sd,
      tau_beta_prior_sd = tau_beta_prior_sd,
      use_lfo_cv = 1
    )
    fit_i = sampling(
      stan_model_ar_hierarchical,
      data = stan_data_i,
      seed = 12452,
      refresh=0,
      iter = 5000,
      control=list(max_treedepth=15)
    )
    last_K_values <- seq(((i-2) * K + 1), ((i - 1) * K))
    loglik_exact_hierarchical[, last_K_values] <- extract_log_lik(fit_i)[, last_K_values]
  }
  
  loglik_exact_hierarchical <- get_lfo_cv_results_hierarchical(2000, 0.5, 10, 0.1)
  exact_elpds_1sap <- apply(loglik_exact_hierarchical, 2, log_mean_exp)
  
  c(ELPD = sum(exact_elpds_1sap[34:99]))
}
#####
# End of the code adapted from http://mc-stan.org/loo/articles/loo2-lfo.html

check_prior_separate <- function(
  full_grouped_data, 
  alpha_prior_mean,
  alpha_prior_sd,
  beta_prior_mean,
  beta_prior_sd
) {
  N = 3000 # number of (succesfull) samples to draw
  K = 11 # number of groups
  D = 10 # number of datapoints (i.e. number of years)
  
  counter_1e7 = 0
  counter_1e6 = 0
  counter_1e5 = 0
  counter_1e4 = 0
  
  # initiaalize an empty array to hold data
  y_pred_prior = array(rep(1, N*K*D), dim=c(N, K, D-1))
  
  for (j in 1:K) { # number of age groups
    for (q in 1:N) {
      while (TRUE) {
        alpha = rnorm(1, alpha_prior_mean, alpha_prior_sd)
        beta = rnorm(1, beta_prior_mean, beta_prior_sd)
        
        passed = TRUE
         # starting with 2nd day becase AR(1) model is used
        for (i in 2:D) {
          mu = alpha + beta * full_grouped_data[j, i-1]
          if (mu < 0) {
            passed = FALSE
            break
          }
        }
        
        if (passed) {
          break
        }
      }
      
      for (i in 2:D) { # starting with 2nd day becase AR(1) model is used
        mu = alpha + beta * full_grouped_data[j, i-1]
        
        if (mu > 0) {
          y_pred = rpois(1, mu)
          
          if (y_pred > 1e7) {
            counter_1e7 = counter_1e7 + 1
          }
          if (y_pred > 1e6) {
            counter_1e6 = counter_1e6 + 1
          }
          if (y_pred > 1e5) {
            counter_1e5 = counter_1e5 + 1
          }
          if (y_pred > 1e4) {
            counter_1e4 = counter_1e4 + 1
          }
  
          y_pred_prior[q, j, i-1] <- y_pred
        }
      }
    }
  }
  
  print(counter_1e7 / (N * K * (D - 1)))
  print(counter_1e6 / (N * K * (D - 1)))
  print(counter_1e5 / (N * K * (D - 1)))
  print(counter_1e4 / (N * K * (D - 1))) 
  
  partial_percentage_hist(y_pred_prior, 1e6)
  partial_percentage_hist(y_pred_prior, 1e5)
  partial_percentage_hist(y_pred_prior, 1e4)
}

# LFO-CV for separate model
get_lfo_cv_results_separate <- function(alpha_prior_sd, beta_prior_sd) {
  N = 10
  L = 4
  K = 11
  
  loglik_exact_separate <- matrix(nrow = 10000, ncol = N * K)
  
  for (i in seq(N, L+1, -1)) {
    full_grouped_data_i <- full_grouped_data[, (1:i)]
    stan_data_i = list(
      N = (i-1) * 11,
      K = 11,
      x = rep(1:nrow(full_grouped_data_i), i - 1),
      y = tail(c(full_grouped_data_i), -11),
      y0 = head(c(full_grouped_data_i), 11),
      alpha_prior_sd = alpha_prior_sd,
      beta_prior_sd = beta_prior_sd,
      use_lfo_cv = 1
    )
    fit_i = sampling(
      stan_model_ar_separate,
      data = stan_data_i,
      seed = 12452,
      refresh=0,
      iter = 5000,
      control=list(max_treedepth=15)
    )
    last_K_values <- seq(((i-2) * K + 1), ((i - 1) * K))
    loglik_exact_separate[, last_K_values] <- extract_log_lik(fit_i)[, last_K_values]
  }
  
  exact_elpds_1sap <- apply(loglik_exact_separate, 2, log_mean_exp)
  c(ELPD = sum(exact_elpds_1sap[34:99]))
}

fit_hierarchical_model <- function(
  mu_group_alpha_prior_sd,
  mu_group_beta_prior_sd,
  tau_alpha_prior_sd,
  tau_beta_prior_sd
) {
  nrows <- nrow(full_grouped_data)
  stan_data = list(
    N = (2018-2010+1) * 11,
    K = 11,
    x = rep(1:nrow(full_grouped_data), 9),
    y = tail(c(full_grouped_data), -11),
    y0 = head(c(full_grouped_data), 11),
    mu_group_alpha_prior_sd = mu_group_alpha_prior_sd,
    mu_group_beta_prior_sd = mu_group_beta_prior_sd,
    tau_alpha_prior_sd = tau_alpha_prior_sd,
    tau_beta_prior_sd = tau_beta_prior_sd,
    use_lfo_cv = 0 
  )
  fit_hierarchical = sampling(
    stan_model_ar_hierarchical,
    data = stan_data,
    seed = 12452,
    refresh = 0,
    chains = 7,
    iter = 6000,
    control=list(max_treedepth=15)
  )
  
  fit_hierarchical
}

fit_separate_model <- function(alpha_prior_sd, beta_prior_sd) {
  nrows <- nrow(full_grouped_data)
  stan_data = list(
    N = (2018-2010+1) * 11,
    K = 11,
    x = rep(1:nrow(full_grouped_data), 9),
    y = tail(c(full_grouped_data), -11),
    y0 = head(c(full_grouped_data), 11),
    alpha_prior_sd = alpha_prior_sd,
    beta_prior_sd = beta_prior_sd,
    use_lfo_cv = 0 
  )
  fit_separate = sampling(
    stan_model_ar_separate,
    data = stan_data,
    seed = 12452,
    refresh=0,
    chains = 7,
    iter = 6000
  )
  
  fit_separate
}

plot_ppc_ribbons <- function(fit, true_data) {
  y_rep <- as.matrix(fit, pars = "y_rep")
  plots <- lapply(
    seq(1, 11),
    function(group_idx) {
      indexes <- seq(group_idx, 99, 11)
      ppc_ribbon(c(true_data[group_idx, (2:10)]), y_rep[, indexes])
    }
  )
  
  grid.arrange(grobs = plots[1:6], ncol = 2)
  grid.arrange(grobs = plots[7:11], ncol = 2) 
}

plot_ppc_intervals <- function(fit, true_data) {
  y_rep <- as.matrix(fit, pars = "y_rep")
  plots <- lapply(
    seq(1, 11),
    function(group_idx) {
      indexes <- seq(group_idx, 99, 11)
      ppc_intervals(c(true_data[group_idx, (2:10)]), y_rep[, indexes])
    }
  )
  
  plots 
}
```


# Introduction

// this part has to be inviting xD
// General talk about Finalnd having high rates of domestic violence, need to raise awareness, etc.

// Main topic/purpose of the project/notebook.

// Present outline of the notebook 

// structure and organization has to be logical

# Data description

Here is a tabular representation of the data.

```{r}
data = read.csv("dataset.csv", header = TRUE, sep=";")
data
```

Below are some utility functions copied from https://github.com/avehtari/BDA_R_demos/blob/master/demos_rstan/stan_utility.R.
The functions are used later mainly for doing model diagnostics of different kinds 

Below are scatter plots for each of the age groups

```{r}
ageGroups <- unique(data$Victim.s.age)
grouped_data <- c()

plots <- lapply(
  seq(1, 11),
  function(i) {
    data_for_age_group <- filter(data, Victim.s.age == ageGroups[i])
     ggplot(aes(Year, Number.of.victims), data = data_for_age_group) +
      geom_point(size = 1)  + geom_line()  
  }
)

grid.arrange(grobs = plots[1:6], ncol = 2)
grid.arrange(grobs = plots[7:11], ncol = 2)
```

Preparing the data

```{r}
full_grouped_data <- sapply(
  2009:2018,
  function (j) sapply(
    1:11,
    function (i) filter(
      data,
      Victim.s.age == ageGroups[i] & Year == j
    )$Number.of.victims
  )
)
full_grouped_data
```

# Analysis problem

# Models

2 models are described in this notebook.

1. Heirarchical AR(1) model

2. Separate AR(1) model

## Model 1

Let's try the complementary non-centered parameterization (the idea to use it to improve the issues mentioned above was adapted from here https://mc-stan.org/users/documentation/case-studies/rstan_workflow.html and here https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html)


```{stan, output.var="stan_model_ar_hierarchical"}
data {
  int<lower=0> N;
  int<lower=0> K; // number of groups
  int<lower=1,upper=K> x[N]; // group indicator
  int<lower=0> y[N];
  int<lower=0> y0[K];
  real<lower=0> mu_group_alpha_prior_sd;
  real<lower=0> mu_group_beta_prior_sd;
  real<lower=0> tau_alpha_prior_sd;
  real<lower=0> tau_beta_prior_sd;
  int<lower=0, upper=1> use_lfo_cv;
}
parameters {
  real mu_group_alpha;
  real<lower=0> mu_group_beta;
  real<lower=0> tau_alpha; // hierarchical std
  real<lower=0> tau_beta; // hierarchical std
  vector[K] alpha_tilde;
  real<lower=0> beta_tilde[K];
}
transformed parameters {
  real<lower=0> mu[use_lfo_cv ? (N - K) : N];
  
  real alpha[K];
  real beta[K];
  
  for (i in 1:K) {
    alpha[i] = mu_group_alpha + tau_alpha * alpha_tilde[i];
    beta[i] = mu_group_beta + tau_beta * beta_tilde[i];
  }
  
  for (n in 1:K) {
    mu[n] = alpha[x[n]] + beta[x[n]] * y0[n];
  }
  
  for (n in K+1:(use_lfo_cv ? (N - K) : N)) {
    mu[n] = alpha[x[n]] + beta[x[n]] * y[n-K];
  }
}
model {
  mu_group_alpha ~ normal(0, mu_group_alpha_prior_sd); // hierarchical prior for mean
  mu_group_beta ~ normal(0, mu_group_beta_prior_sd); // hierarchical prior for mean
  tau_alpha ~ cauchy(0, tau_alpha_prior_sd); // hierarchical prior for std
  tau_beta ~ cauchy(0, tau_beta_prior_sd); // hierarchical prior for std
  
  alpha_tilde ~ normal(0, 1);
  beta_tilde ~ normal(0, 1);
  
  for (n in 1:(use_lfo_cv ? (N - K) : N)) {
     y[n] ~ poisson(mu[n]);
  }
}
generated quantities {
  vector[N] log_lik;
  real<lower=0> mu_pred[use_lfo_cv ? K : 0];
  vector[use_lfo_cv ? 0 : N] y_rep;
  
  if (use_lfo_cv) {
    for (n in 1:K) {
      mu_pred[n] = alpha[n] + beta[n] * y[(N - K) - K + n];
    }
    
    for (i in 1:(N - K)) {
      log_lik[i] = poisson_lpmf(y[i] | mu[i]);
    }
    
    for (i in 1:K) {
      log_lik[(N - K) + i] = poisson_lpmf(y[(N - K) + i] | mu_pred[i]);
    }
  } else {
    for (i in 1:N) {
      y_rep[i] = poisson_rng(mu[i]);
      log_lik[i] = poisson_lpmf(y[i] | mu[i]);
    }
  }
}
```

### Prior predictive checking

```{r}
check_prior_hierarchical(full_grouped_data, 20000, 20, 5000, 20)
```

```{r}
check_prior_hierarchical(full_grouped_data, 20000, 5, 1000, 2)
```

```{r}
check_prior_hierarchical(full_grouped_data, 10000, 2, 200, 2)
```

The latter prior seems to be the most reasonable one. About 52.5% of the mass lies between 0 and 10000. About 6% of the mass is with values > 100000.

This is vage enough and reasonably constrained at the same time.

### Model diagnostics

```{r}
fit_hierarchical <- fit_hierarchical_model(10000, 2, 200, 2)
print(fit_hierarchical)
```

#### Effective sample size

According to BDA3 Chapter 11.5, it is generally sufficient to have 10 times number of chains effective sample sizes to obtain a reasonable precision from the simulation. Since we're using 7 chains (as can be seen from the output above), we need to make sure that there are at least 7 * 10 = 70 effective sample sizes for each of the parameters.

As can be seen, all parameters have $\hat n_{eff}$ greater than *3700*, which is clearly sufficient given the recommended value of 70.

Besides, according to https://mc-stan.org/users/documentation/case-studies/rstan_workflow.html, "When $n_{eff} / n_{transitions} < 0.001$ the estimators that we use are often biased and can significantly overestimate the true effective sample size.". For our case, the lowest ratio is 3700 / 21000 = 0.176 when taking all post-warmup draws as $n_{transitions}$.

Thus, we can consider our simulation precise enough based on the $\hat n_{eff}$ values.

#### R hat diagnostics

The below interpretation is partially based on the information given in BDA3 chapter 11 and on RStan
documentation (see https://rdrr.io/cran/rstan/man/Rhat.html)

$\hat R$ represents the potential scale reduction factor. $\hat R$ of the values provide convergence diagnostic for - in
this case - 10 chains. It compares “within- and between- chain estimates for model parameters and other
univariate quantities of interest”. If $\hat R$ is not near 1, we need either to coninue our simulations further or to
change the algorithm to be more efficient. How close we want $\hat R$ to be to 1 depends on a problem at hand,
but values smaller than 1.1 or even 1.01 to be safe are generally considered as acceptable

As can be seen from the output above, $\hat R$ for all of the parameters is either 1 or very close to 1. In particular, the values are smaller than a recommended threshold of 1.1 (BDA3 Chapter 11.5).

*We can conclude from this and the previously done ESS diagnostic* that the sequences converged well and we don't need to run the simulations further.

#### HMC -specific convergence diagnostics

The utility function below prints the number of iterations that sanurated the maximum tree depth (set to 15 in this case), and the number of iterations that ended with a divergence.

The utility function uses the code from https://github.com/avehtari/BDA_R_demos/blob/master/demos_rstan/stan_utility.R

```{r}
print_fit_diagnostic(fit_hierarchical, 10)
print_fit_diagnostic(fit_hierarchical, 15)
```

Quoting from https://mc-stan.org/users/documentation/case-studies/rstan_workflow.html, "The dynamic implementation of Hamiltonian Monte Carlo used in Stan has a maximum trajectory length built in to avoid infinite loops that can occur for non-identified models. For sufficiently complex models, however, Stan can saturate this threshold even if the model is identified, which limits the efficacy of the sampler."

As can be seen from the output above, 29 iterations saturated the tree depth of 10. However, as can be noticed the fitting was run with maximum tree depth of 15. With tree-depth set to 15, there are 0 saturations.

Thus, we can conclude that having max. tree depth set to 15, allows NUTS to not be terminated prematurely and thus the efficientcy of our sampling algorithm is not being restricted.

Besides, we can see that 0 iterations ended with a divergence in the fitting above. Divergences in a simulation might be a indicator of pathological neighbourhoodsof the posterior that the simulated Hamiltonian trajectories are not able to explore sufficiently well (see https://mc-stan.org/users/documentation/case-studies/rstan_workflow.html). 

We thus can conclude that there are no apparent issues with divergences which means that the simulation was able to explore all the important parts of the posterior sufficiently well.

#### PSIS-LOO and LFO

```{r}
loo_hierarchical <- get_loo_diagnostics(fit_hierarchical)
print(loo_hierarchical)
plot(loo_hierarchical)
```

```{r}
exact_elpd_hierarchical <- get_lfo_cv_results_hierarchical(10000, 2, 200, 2)
rbind_print(
  "LFO" = exact_elpd_hierarchical
)
```

### Graphical posterior predictive checking

Below are the plots of of the true data plotted against 21000 draws from the posterior of the model. The draws from the posterior are summarised using "ribbons" plots.

```{r}
plot_ppc_ribbons(fit_hierarchical, full_grouped_data)
```

We can see from the plots that the draws from the model do not overlap with the actual data in many cases. Moreover, it seems that the model is way too confident with most of the groups resulting in way too narrow "ribbons" in plots above that do not match with the data.

It can also be observed that in many cases predictions for point $y$ are closer to the true value of $y-1$ than to the true value of $y$. This can be explained by the constraints of the selected model (AR(1)) where a predicted value of $y$ highly depends on the true value of the (chronologically) previous datapoint.

To demonstrate further that the model appears to be too confident, we plot the same data (only some age groups, the reset were omitted for brevity) using "ppc_intervals" function (see below).

```{r}
plot_ppc_intervals(fit_hierarchical, full_grouped_data)
```


Finally, in order to demonstrate further how wrong is the model, the error scatter plot is plotted below demonstrating average errors (of y_pred when compared to the actual data) for each datapoint in each age group.

```{r}
y_rep <- as.matrix(fit_hierarchical, pars = "y_rep")
ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), y_rep)
```

We can see that for most of the datapoinst, the average error is below 150. Moreover, approximately the same number of data points have negative error as the number of datapoints that have positive average error. it also can be noted that there is moer variation in values of average error for datapoints whose true value is above 1000 with extreme cases being -350 and just under 500.

*From everything discussed above in the seciton, we can conclude that* the model is quite poor in terms of how it fits the data. From the simple visualizaions shown above, we can assume that the main reasons for this is:

1. Uncertainty intervals are not wide enough
2. The fact that data depends mainly on hte previous observation only (because of AR(1)), since data changes quite a bit on some occasions for the year $y$ compared to the year $y-1$.

### Prior sensitivity analysis

Now let's try another sensible but a little wider prior, while keeping results of the previous fit as our base-line.

```{r}
fit_hierarchical_wide_prior = fit_hierarchical_model(10000, 25, 2000, 25) # wider prior
print(fit_hierarchical_wide_prior)
```

```{r}
print_fit_diagnostic(fit_hierarchical_wide_prior, 15)
```

```{r}
loo_hierarchical_wide_prior <- get_loo_diagnostics(fit_hierarchical_wide_prior)
print(loo_hierarchical_wide_prior)
plot(loo_hierarchical_wide_prior)
```

```{r}
plot_ppc_ribbons(fit_hierarchical_wide_prior, full_grouped_data)
```

```{r}
plot_ppc_intervals(fit_hierarchical_wide_prior, full_grouped_data)
```

```{r}
exact_elpd_hierarchical_wide_prior <- get_lfo_cv_results_hierarchical(10000, 25, 2000, 25)
rbind_print(
  "LFO" = exact_elpd_hierarchical_wide_prior
)
```


Now let's try a stronger more narrow prior

```{r}
fit_hierarchical_narrow_prior = fit_hierarchical_model(2000, 0.5, 10, 0.1)
print(fit_hierarchical_narrow_prior)
```

```{r}
print_fit_diagnostic(fit_hierarchical_narrow_prior, 15)
```

```{r}
loo_hierarchical_narrow_prior <- get_loo_diagnostics(fit_hierarchical_narrow_prior)
print(loo_hierarchical_narrow_prior)
plot(loo_hierarchical_narrow_prior)
```

```{r}
plot_ppc_ribbons(fit_hierarchical_narrow_prior, full_grouped_data)
```

```{r}
plot_ppc_intervals(fit_hierarchical_narrow_prior, full_grouped_data)
```

```{r}
exact_elpd_hierarchical_narrow_prior <- get_lfo_cv_results_hierarchical(2000, 0.5, 10, 0.1)
rbind_print(
  "LFO" = exact_elpd_hierarchical_narrow_prior
)
```

```{r}
y_rep <- as.matrix(fit_hierarchical, pars = "y_rep")
y_rep_wide_prior <- as.matrix(fit_hierarchical_wide_prior, pars = "y_rep")
y_rep_narrow_prior <- as.matrix(fit_hierarchical_narrow_prior, pars = "y_rep")
plot_baseline = ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), y_rep)
plot_wide_prior = ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), y_rep_wide_prior)
plot_narrow_prior = ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), y_rep_narrow_prior)

plot(plot_wide_prior)
plot(plot_baseline)
plot(plot_narrow_prior)
```

// include proper prior, jusify

// Rhat convergence diagnostics

// HMC specific convergence diagnostics (divergences, tree depth)

// ESS diagnostics

// posterior predictive checking

## Model 2

```{stan, output.var="stan_model_ar_separate"}
data {
  int<lower=0> N;
  int<lower=0> K; // number of groups
  int<lower=1,upper=K> x[N]; // group indicator
  int<lower=0> y[N];
  int<lower=0> y0[K];
  real<lower=0> alpha_prior_sd;
  real<lower=0> beta_prior_sd;
  int<lower=0, upper=1> use_lfo_cv;
}
parameters {
  real alpha[K];
  real<lower=0> beta[K];
}
transformed parameters {
  real<lower=0> mu[use_lfo_cv ? (N - K) : N];
  
  for (n in 1:K) {
    mu[n] = alpha[x[n]] + beta[x[n]] * y0[n];
  }
  
  for (n in K+1:(use_lfo_cv ? (N - K) : N)) {
    mu[n] = alpha[x[n]] + beta[x[n]] * y[n-K];
  }
}
model {
  for (n in 1:K) {
    alpha[n] ~ normal(0, alpha_prior_sd); // prior
    beta[n] ~ normal(0, beta_prior_sd);  // prior
  }
  
  for (n in 1:(use_lfo_cv ? (N - K) : N)) {
     y[n] ~ poisson(mu[n]);
  }
}
generated quantities {
  vector[N] log_lik;
  real<lower=0> mu_pred[use_lfo_cv ? K : 0];
  vector[use_lfo_cv ? 0 : N] y_rep;
  
  if (use_lfo_cv) {
    for (n in 1:K) {
      mu_pred[n] = alpha[n] + beta[n] * y[(N - (1 * K)) - K + n];
    }
    
    for (i in 1:(N - (1 * K))) {
      log_lik[i] = poisson_lpmf(y[i] | mu[i]);
    }
    
    for (i in 1:K) {
      log_lik[(N - (1 * K)) + i] = poisson_lpmf(y[(N - (1 * K)) + i] | mu_pred[i]);
    }
  } else {
    for (i in 1:N) {
      y_rep[i] = poisson_rng(mu[i]);
      log_lik[i] = poisson_lpmf(y[i] | mu[i]);
    }
  }
}
```


### Prior predictive checking

```{r}
check_prior_separate(full_grouped_data, 0, 10000, 0, 2)
```

```{r}
check_prior_separate(full_grouped_data, 0, 10000, 1, 1)
```

```{r}
check_prior_separate(full_grouped_data, 0, 10000, 0, 25)
```

```{r}
check_prior_separate(full_grouped_data, 0, 30000, 0, 2)
```


```{r}
fit_separate = fit_separate_model(10000, 2)
print(fit_separate)
```

```{r}
print_fit_diagnostic(fit_separate, 10)
```

*PSIS-LOO*

```{r}
loo_separate <- get_loo_diagnostics(fit_separate)
print(loo_separate)
plot(loo_separate)
```

*LFO-LOO*

```{r}
exact_elpd_separate <- get_lfo_cv_results_separate(10000, 2)
rbind_print(
  "LFO" = exact_elpd_separate
)
```

### Graphical posterior predictive checking

```{r}
plot_ppc_ribbons(fit_separate, full_grouped_data)
```

```{r}
plot_ppc_intervals(fit_separate, full_grouped_data)
```

```{r}
y_rep <- as.matrix(fit_separate, pars = "y_rep")
ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), y_rep)
```

### Prior sensitivity analysis

Now let's try another sensible but a little wider prior, while keeping results of the previous fit as our base-line.
```{r}
fit_separate_wide_prior = fit_separate_model(10000, 25)
print(fit_separate_wide_prior)
```

```{r}
print_fit_diagnostic(fit_separate_wide_prior, 10)
```

```{r}
loo_separate_wide_prior <- get_loo_diagnostics(fit_separate_wide_prior)
print(loo_separate_wide_prior)
plot(loo_separate_wide_prior)
```


```{r}
plot_ppc_ribbons(fit_separate_wide_prior, full_grouped_data)
```

```{r}
exact_elpd_separate_wide_prior <- get_lfo_cv_results_separate(10000, 25)
rbind_print(
  "LFO" = exact_elpd_separate_wide_prior
)
```

Now let's try a stronger more narrow prior

```{r}
fit_separate_narrow_prior = fit_separate_model(2000, 0.5)
print(fit_separate_narrow_prior)
```

```{r}
print_fit_diagnostic(fit_separate_narrow_prior, 10)
```

```{r}
loo_separate_narrow_prior <- get_loo_diagnostics(fit_separate_narrow_prior)
print(loo_separate_narrow_prior)
plot(loo_separate_narrow_prior)
```

```{r}
exact_elpd_separate_narrow_prior <- get_lfo_cv_results_separate(2000, 0.5)
rbind_print(
  "LFO" = exact_elpd_separate_narrow_prior
)
```

```{r}
y_rep <- as.matrix(fit_separate, pars = "y_rep")
y_rep_wide_prior <- as.matrix(fit_separate_wide_prior, pars = "y_rep")
y_rep_narrow_prior <- as.matrix(fit_separate_narrow_prior, pars = "y_rep")
plot_baseline = ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), y_rep)
plot_wide_prior = ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), y_rep_wide_prior)
plot_narrow_prior = ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), y_rep_narrow_prior)

plot(plot_wide_prior)
plot(plot_baseline)
plot(plot_narrow_prior)
```

## Model comparison

Here is a comparison for hierarchical and separate model respectively

```{r}
ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), as.matrix(fit_hierarchical, pars = "y_rep"))
ppc_error_scatter_avg(c(full_grouped_data[, (2:10)]), as.matrix(fit_separate, pars = "y_rep"))
```

```{r}
comparison_results = matrix(
  c(
    loo_hierarchical$estimates[1:2], # PSIS-LOO -based elpd and p_eff values
    exact_elpd_hierarchical, # LFO-based elpd
    loo_hierarchical_wide_prior$estimates[1:2], # PSIS-LOO -based elpd and p_eff values
    exact_elpd_hierarchical_wide_prior, # LFO-based elpd
    loo_hierarchical_narrow_prior$estimates[1:2], # PSIS-LOO -based elpd and p_eff values
    exact_elpd_hierarchical_narrow_prior, # LFO-based elpd
    loo_separate$estimates[1:2], # PSIS-LOO -based elpd and p_eff values
    exact_elpd_separate, # LFO-based elpd
    loo_separate_wide_prior$estimates[1:2], # PSIS-LOO -based elpd and p_eff values
    exact_elpd_separate_wide_prior, # LFO-based elpds
    loo_separate_narrow_prior$estimates[1:2], # PSIS-LOO -based elpd and p_eff values
    exact_elpd_separate_narrow_prior # LFO-based elpd
  ),
  ncol = 6,
  dimnames = list(
    c("elpd_loo", "p_loo", "elpd_lfo"),
    c("hierarchical",
      "hierarchical (wide prior)",
      "hierarchical (narrow prior)",
      "separate",
      "separate (wide prior)",
      "separate (narrow prior)")
  )
)
comparison_results
```

```{r}
kable(comparison_results)
```

// include proper prior, jusify

// Rhat convergence diagnostics

// HMC specific convergence diagnostics (divergences, tree depth)

// ESS diagnostics

// posterior predictive checking

# Problems encountered and potential improvements


# Conclusion

// a clear conclusion here
